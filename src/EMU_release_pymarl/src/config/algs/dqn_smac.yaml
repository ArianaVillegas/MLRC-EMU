# --- DQN specific parameters ---

action_selector: "epsilon_greedy"
epsilon_start: 1.0
epsilon_finish: 0.05
epsilon_anneal_time: 200000

runner: "episode"

buffer_size: 5000

target_update_interval: 200

agent_output_type: "q"
learner: "dqn_learner"
double_q: True

mixer: "qmix"
mixing_embed_dim: 32
hypernet_embed: 64

target_update_freq: 500
batch_size: 32
gamma: 0.99
learning_rate: 0.0005

exploration_final_eps: 0.05
exploration_fraction: 0.1

dqn_replay_buffer_size: 1000000
dqn_learning_starts: 10000
dqn_train_freq: 1
dqn_gradient_steps: 1

dqn_target_network_update_freq: 500
dqn_prioritized_replay: False

ec_buffer_stats_update_interval: 200
ec_buffer_embedder_update_interval: 10000
emb_training_batch: 102400
emb_training_mini_batch: 1024
t_EC_update: 0
buffer_size_update: 5000

rtol_memory: 0.0
atol_memory: 0.0013

memory_emb_type: 3
emb_out_type: 3
encoder_type: 1
use_AEM: True
flag_stats_norm: True
delta_cover_type: 1
fixed_delta: True
additional_update: True
optimality_incentive: True
optimality_type: 1
flag_memory_cnt_reset: False
flag_init_desirability: False

lambda_s: 0.1
lambda_kl: 0.0001

num_circle: 1
curiosity_scale: 0.0
curiosity_decay: True
curiosity_decay_rate: 0.95
curiosity_decay_cycle: 100000
curiosity_decay_stop: 0.01

task: "smac"
smac_map: "3s5z_vs_3s6z"

save_buffer: False

mac: "fast_mac"
agent: "rnn_fast"
use_individual_Q: False
individual_q_loss_weight: 0.01

is_prioritized_buffer: False
use_emdqn: True
emdqn_loss_weight: 0.1

ep_replay_buffer_size: 1000000
ep_latent_dim: 4

soft_update_tau: 0.005
vdn_soft_update: True
predict_vdn_target: True
predict2_vdn_target: True
use_qtotal_td: False

name: "DQN_SMAC_3s5z_vs_3s6z"
